<a name=top></a><!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Homepage Zhuo Liu</title><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css><link rel=stylesheet href=/css/style.css><link rel=stylesheet href=/css/fonts.css><link href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/github.min.css rel=stylesheet><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/highlight.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/languages/r.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/languages/bash.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/languages/python.min.js></script><script src=https://cdn.jsdelivr.net/npm/vega@5.17.0></script><script src=https://cdn.jsdelivr.net/npm/vega-lite@4.17.0></script><script src=https://cdn.jsdelivr.net/npm/vega-embed@6.12.2></script><script>hljs.initHighlightingOnLoad();</script><link rel=icon href=https://joeliuz6.github.io/media/logo.png></head><body><div class=wrapper><header class=header><nav class=nav><a href=/ class=nav-logo><img src=/media/logo.png width=50 height=50 alt=Z6></a><ul class=nav-links><li><a href=/>Home</a></li><li><a href=/en/research/>Research</a></li><li><a href=/en/blog/>Blog</a></li><li><a href=/cn/posts/>中文</a></li></ul></nav></header><main class=content role=main><div style=text-align:center><h1>Towards Flexible Fairness-accuracy Tradeoff With Label Constraints</h1><p>Zhuo Liu</p><hr></div><span class=article-toolbar><a href=https://github.com/joeliuz6/joeliuz6.github.io/edit/master/content/en/Blog/fairness_eval.md style=font-size:24px;color:#000 target=_blank><i class="fa fa-edit" aria-hidden=true title="Suggest an edit of this page"></i></a></span><div class="body-text list-text"><h1 id=introduction-whats-fairness>Introduction: What&rsquo;s fairness?<a href=#introduction-whats-fairness class=header-anchor arialabel=Anchor> #</a></h1><p>The concept &ldquo;fairness&rdquo; was first proposed in about late 2000s, attracting a wide interest together with ethical AI in the last decade. In general, fairness can be divided into three categories: group fairness, individual fairness and conterfactual fairness, where the former two are statistical dependence measures and the latter is rooted in causal inference. So how do we define fairness?</p><h2 id=values-of-fairness-in-real-world-applications>Values of fairness in real-world applications<a href=#values-of-fairness-in-real-world-applications class=header-anchor arialabel=Anchor> #</a></h2><h2 id=fairness-accuracy-tradeoff>Fairness-Accuracy tradeoff<a href=#fairness-accuracy-tradeoff class=header-anchor arialabel=Anchor> #</a></h2><h1 id=regularization-and-inference-with-label-constraints>Regularization and inference with label constraints<a href=#regularization-and-inference-with-label-constraints class=header-anchor arialabel=Anchor> #</a></h1><ul><li>Regularization with label constraints</li><li>On-training approach: Inference-based training</li><li>Learning plus inference</li></ul><h1 id=achieve-flexible-fairness-accuracy-tradeoff-at-test-time>Achieve flexible fairness-accuracy tradeoff at test time<a href=#achieve-flexible-fairness-accuracy-tradeoff-at-test-time class=header-anchor arialabel=Anchor> #</a></h1><h2 id=learning-with-constraints>Learning with constraints<a href=#learning-with-constraints class=header-anchor arialabel=Anchor> #</a></h2><ul><li>YOTO</li><li>YODO</li></ul><h2 id=inference-with-constraints>Inference with constraints<a href=#inference-with-constraints class=header-anchor arialabel=Anchor> #</a></h2><div class=reminder><h1 id=references>References<a href=#references class=header-anchor arialabel=Anchor> #</a></h1><ul><li><a href="https://openreview.net/pdf?id=HyxY6JHKwr" target=_blank rel="noreferrer noopener">You Only Train Once: Loss-Conditional Training of Deep Networks</a></li><li><a href=https://openreview.net/pdf/1d2e9e0624d323f4f45aa471f7195aa6b466edaf.pdf target=_blank rel="noreferrer noopener">Dataset Fairness: Achievable Fairness On Your Data With Utility Guarantees</a></li><li><a href=https://arxiv.org/pdf/2307.03886.pdf target=_blank rel="noreferrer noopener">On Regularization and Inference with Label Constraints</a></li><li><a href=https://arxiv.org/pdf/1707.09457.pdf target=_blank rel="noreferrer noopener">Men Also Like Shopping:Reducing Gender Bias Amplification using Corpus-level Constraints</a></div></li></ul><p style=color:#777>Last modified on 0001-01-01</p></div><a href=#top><i class="fa fa-chevron-up" style=font-size:30px;color:#000></i></a></main><footer class=footer><script type=text/javascript src=/js/math-code.js></script><script async src="//mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script><script type=text/javascript src=/js/center-img.js></script><ul class=footer-links><li><a href=/en/posts/index.xml type=application/rss+xml title="RSS feed">Subscribe</a></li><li><a href=http://creativecommons.org/licenses/by-nc-sa/4.0/ target=_blank>License
<i class="fa fa-cc" aria-hidden=true title="Attribution-NonCommercial-ShareAlike 4.0 International"></i></a></li></ul><div class=copyright-text>©
Zhuo Liu
2020-2024</div></footer>